{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b64148-0bd3-4403-bab3-e7cda6c5ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import STL10\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "import sys\n",
    "\n",
    "'''\n",
    "This script is for performing a hyperparameter search \n",
    "for encoder fintuning.\n",
    "'''\n",
    "\n",
    "if len(sys.argv) != 4:\n",
    "    print(\"Usage: python ae_pretraining.py learning_rate batch_size weight_decay\")\n",
    "    print(sys.argv)\n",
    "    sys.exit()\n",
    "\n",
    "learning_rate = float(sys.argv[1])\n",
    "batch_size = int(sys.argv[2])\n",
    "weight_decay = float(sys.argv[3])\n",
    "\n",
    "image_size = 96\n",
    "\n",
    "# Create a new transformation that resizes the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    # Convert the PIL Image to Torch Tensor before RandomErasing\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.2, 0.33), ratio=(0.3, 0.3), value='random'),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load STL-10 dataset\n",
    "train_dataset = STL10(root='./data', split='train', transform=transform, download=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = STL10(root='./data', split='test', transform=transform, download=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "nc = 3\n",
    "ndf = 96\n",
    "num_epochs = 100\n",
    "lr=learning_rate\n",
    "beta1 = 0.5\n",
    "ngpu = 1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, ngpu, dim_z, num_classes):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        nc = 3  # Number of input channels for the 96x96x3 image\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 96 x 96\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size: (ndf) x 48 x 48\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size: (ndf*2) x 24 x 24\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size: (ndf*4) x 12 x 12\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size: (ndf*8) x 6 x 6\n",
    "            nn.Conv2d(ndf * 8, dim_z, 6, 1, 0, bias=False)\n",
    "        )\n",
    "        self.fc = nn.Linear(dim_z, num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        z = self.main(input)\n",
    "        z = z.view(input.size(0), -1)  # Flatten z to (batch_size, dim_z)\n",
    "        c = self.fc(z)\n",
    "        return c\n",
    "\n",
    "# Load Pretrained Weights\n",
    "encoder = Encoder(ngpu=0, dim_z=64, num_classes=10).to(device)\n",
    "PATH='/data/users2/jwardell1/dcgan-project/models/ae_pretraining_0.0001_256_0.0004.pth'\n",
    "encoder.main.load_state_dict(torch.load(PATH))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# set up wandb\n",
    "wandb.login()\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"dcgan-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"architecture\": \"Encoder Finetuning\",\n",
    "    \"dataset\": \"STL-10\",\n",
    "    \"epochs\": num_epochs,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "best_loss = float('inf')\n",
    "best_model_state = None\n",
    "\n",
    "\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_value = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    # Set Network to Train Mode\n",
    "    encoder.train()\n",
    "\n",
    "    # For each batch in the dataloader\n",
    "    for i, (data, labels) in enumerate(train_loader, 0): \n",
    "        data_real = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = encoder(data_real)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = torch.argmax(output.data, dim=1).to(device)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        \n",
    "        train_correct += correct\n",
    "        train_loss_value += loss.item()\n",
    "        \n",
    "        train_accuracy = train_correct / len(train_dataset)\n",
    "        print(f'iteration {i} current loss: {loss.item()} current acc: {train_accuracy}')\n",
    "\n",
    "\n",
    "    wandb.log({\"TrainAccuracy\": train_accuracy})\n",
    "\n",
    "    train_loss = train_loss_value / len(train_loader)\n",
    "    wandb.log({\"TrainLoss\": loss.item()})\n",
    "\n",
    "\n",
    "    print(f'\\t\\tTrain Epoch {epoch}/{num_epochs},Train Accuracy: {train_accuracy}, Train Loss: {train_loss}.')\n",
    "\n",
    "\n",
    "\n",
    "    # Validation Step\n",
    "    print('Starting Validation Loop...')\n",
    "    val_correct = 0\n",
    "    val_loss_value = 0\n",
    "    val_running_total = 0\n",
    "\n",
    "    # Set the model to valuation mode\n",
    "    encoder.eval()\n",
    "\n",
    "\n",
    "    # Iterate over the validation dataset in batches\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "\n",
    "            # Put val data to device (CPU, GPU, or TPU)\n",
    "            data_real = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "\n",
    "            # Forward pass batch through D\n",
    "            output = encoder(data_real)\n",
    "\n",
    "            # Calculate loss on validation batch\n",
    "            v_loss = criterion(output, labels)\n",
    "\n",
    "            # Compute Predicted Labels for a Batch in Validation Dataset\n",
    "            predicted = torch.argmax(output.data, dim=1).to(device)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update Val Data\n",
    "            val_loss_value += v_loss.item()\n",
    "\n",
    "\n",
    "    val_accuracy = val_correct / len(test_dataset)\n",
    "    wandb.log({\"ValidationAccuracy\": val_accuracy})\n",
    "\n",
    "    \n",
    "    val_loss = val_loss_value / len(test_loader)\n",
    "    wandb.log({\"ValidationLoss\": val_loss})\n",
    "\n",
    "    print(f\"\\t\\tValidation Epoch {epoch}/{num_epochs}, Validation Accuracy: {val_accuracy}, Validation Loss: {val_loss}\")\n",
    "\n",
    "    # Update best model if this epoch had the higest accuracy so far\n",
    "    if train_loss < best_loss:\n",
    "        best_loss = train_loss\n",
    "        print(f'best loss {best_loss}')\n",
    "        best_model_state = encoder.main.state_dict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "if best_model_state is not None:\n",
    "    PATH = '../models/finetuned_encoder_weights_da_{}_{}_{}.pth'.format(learning_rate, batch_size, weight_decay)\n",
    "    torch.save(best_model_state, PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
